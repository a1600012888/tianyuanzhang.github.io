<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tianyuan Zhang</title>

  <meta name="author" content="Tianyuan Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/pku.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:1.5%;width:60%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Tianyuan Zhang 「张天远」</name>
                  </p>
                  <p>I am a second-year master student in Robotics Institute at CMU, supervised by <a
                      href="http://www.cs.cmu.edu/~srinivas/"> Prof.
                      Srinivasa Narasimhan</a>.
                    Previously, I finished my undergraduate in School of EECS at Peking
                    University, working with <a href="https://scholar.google.co.uk/citations?user=a2sHceIAAAAJ&hl=en">
                      Prof. Zhanxing Zhu</a>
                    <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&hl=zh-CN" Dr. Xiangyu Zhang></a>,
                    and
                    <a href="https://hangzhaomit.github.io/"> Prof. Hang Zhao</a>.
                    <br>
                    I will be joining MIT CSAIL as a PhD student in 2023 Fall.
                  </p>
                  <p>
                    I work on computational imaging, and computer vision.
                  </p>
                  <p>Email: tianyuaz [at] andrew [dot] cmu [dot] edu
                  </p>
                  <p style="text-align:center">
                    <a href="data/cv_nov_2022.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=uJocZjkAAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/a1600012888">Github</a>&nbsp/&nbsp
                    <a href="portfolio.html" target="_blank">
                      Attempts at photography</a> &nbsp&nbsp&nbsp&nbsp
                  </p>
                </td>
                <td style="padding:1.5%;width:60%;max-width:60%">
                  <a href="images/selffile_ny.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/selffile_ny.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    I'm interested in physiscs-based vision, computational imaging and computer graphics.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="impact_stop()" onmouseover="impact_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='impact_img'>
                      <img src='images/impact_cvpr_thubnail.gif' height="153" width="184">
                    </div>
                    <img src='images/impact_cvpr_thubnail.gif' height="153" width="184">
                  </div>
                  <script type="text/javascript">
                    function impact_start() {
                      document.getElementById('impact_img').style.opacity = "1";
                    }

                    function impact_stop() {
                      document.getElementById('impact_img').style.opacity = "0";
                    }
                    dreamfusion_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://tianyuanzhang.com/projects/impactlocalization/">
                    <papertitle>Analyzing Physical Impacts using Transient Surface Wave Imaging</papertitle>
                  </a>
                  <br>
                  <strong>Tianyuan Zhang</strong>,
                  Mark Sheinin, Dorian Chan, Mark Rau,
                  <br>
                  Matthew O'Toole, Srinivasa G. Narasimhan.
                  <br>
                  <em>CVPR</em>, 2023
                  <br>
                  <a href="https://tianyuanzhang.com/projects/impactlocalization/">project page</a>
                  /
                  <a
                    href="https://github.com/a1600012888/Analyzing-Physical-Impacts-using-Transient-Surface-Wave-Imaging">github</a>
                  /
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Analyzing_Physical_Impacts_Using_Transient_Surface_Wave_Imaging_CVPR_2023_paper.pdf">paper</a>
                  /
                  <a href="https://youtu.be/qm-3XCkP-XM">videos</a>
                  <p></p>
                  <p>
                    We image the "ripples" on solid surfaces caused by physical impacts, which contain information about
                    the object's physical properties and its interaction with the environment.
                    We showcase non-line-of-sight impact localization capabilities.
                  </p>
                </td>
              </tr>

              <tr onmouseout="rife_stop()" onmouseover="rife_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='rife_gif'>
                      <img src='images/rife/rife_demo.gif' height="128" width="184">
                    </div>
                    <img src='images/rife/rife_demo.gif' height="128" width="184">
                  </div>
                  <script type="text/javascript">
                    function rife_start() {
                      document.getElementById('rife_gif').style.opacity = "1";
                    }

                    function rife_stop() {
                      document.getElementById('rife_gif').style.opacity = "0";
                    }
                    dreamfusion_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/megvii-research/ECCV2022-RIFE/">
                    <papertitle>Real-Time Intermediate Flow Estimation for Video Frame Interpolation</papertitle>
                  </a>
                  <br>
                  Zhewei Huang,
                  <strong>Tianyuan Zhang</strong>,
                  Wen Heng, Boxin Shi, Shuchang Zhou
                  <br>
                  <em>ECCV</em>, 2022
                  <br>
                  <a href="https://github.com/megvii-research/ECCV2022-RIFE/">github</a>
                  /
                  <a href="https://arxiv.org/abs/2011.06294">arXiv</a>
                  /
                  <a href="https://www.youtube.com/results?search_query=rife+interpolation&sp=CAM%253D">demos</a>
                  <p></p>
                  <p>
                    We propose a real-time intermediate flow estimation (RIFE) method for video frame interpolation, it
                    runs 30+FPS
                    for 2X 720p interpolation on a 2080Ti GPU
                  </p>
                </td>
              </tr>

              <tr onmouseout="sst_stop()" onmouseover="sst_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='sst_image'>
                      <img src='images/sst/sst.png' width="180">
                    </div>
                    <img src='images/sst/sst.png' width="180">
                  </div>
                  <script type="text/javascript">
                    function sst_start() {
                      document.getElementById('sst_image').style.opacity = "1";
                    }

                    function sst_stop() {
                      document.getElementById('sst_image').style.opacity = "0";
                    }
                    sst_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/tusen-ai/SST">
                    <papertitle>Embracing Single Stride 3D Object Detector with Sparse Transformer
                    </papertitle>
                  </a>
                  <br>
                  Lue Fan, Ziqi Pang,
                  <strong>Tianyuan Zhang</strong>,
                  Yu-Xiong Wang, Hang Zhao, Feng Wang, Naiyang Wang, Zhaoxiang Zhang
                  <br>
                  <em>CVPR</em>, 2022
                  <br>
                  <a href="https://github.com/tusen-ai/SST">github</a> /
                  <a href="https://arxiv.org/abs/2112.06375">arxiv</a> /
                  <p></p>
                  <p>
                    In contrast to 2D, object size in 3D does not exhibit long-tail distributions. We propose a single
                    stride sparse Transformer (SST) for 3D object detection. We obtained impressive results on small
                    objects
                  </p>
                </td>
              </tr>

              <tr onmouseout="detr3d_stop()" onmouseover="det3d_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='detr3d_image'>
                      <img src='images/detr3d/figure_detr3d.png' width="180">
                    </div>
                    <img src='images/detr3d/figure_detr3d.png' width="180">
                  </div>
                  <script type="text/javascript">
                    function detr3d_start() {
                      document.getElementById('pnf_image').style.opacity = "1";
                    }

                    function detr3d_stop() {
                      document.getElementById('pnf_image').style.opacity = "0";
                    }
                    detr3d_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2110.06922">
                    <papertitle>DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries</papertitle>
                  </a> <br>
                  Yue Wang, Vitor Guizilini*,
                  <strong>Tianyuan Zhang*</strong>,
                  Yilun Wang, Hang Zhao, Justin Solomon
                  <br>
                  <em>CoRL</em>, 2021
                  <br>
                  <a href="https://github.com/WangYueFt/detr3d">github</a> /
                  <a href="https://arxiv.org/abs/2110.06922">arxiv</a> /
                  <p>
                    A new paradigm of 3D object detection from multiview 2D images
                  </p>
                </td>
              </tr>

              <tr onmouseout="mutr_stop()" onmouseover="mutr_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='mutr3d_gif'>
                      <img src='images/mutr3d/mutr3d.gif' width="180">
                    </div>
                    <img src='images/mutr3d/mutr3d.gif' width="180">
                  </div>
                  <script type="text/javascript">
                    function mutr_start() {
                      document.getElementById('mutr3d_gif').style.opacity = "1";
                    }

                    function mutr_stop() {
                      document.getElementById('mutr3d_gif').style.opacity = "0";
                    }
                    dreamfusion_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2205.00613">
                    <papertitle>MUTR3D: A Multi-camera Tracking Framework via 3D-to-2D Queries</papertitle>
                  </a>
                  <br>
                  <strong>Tianyuan Zhang</strong>,
                  Xuanyao Chen,
                  Yue Wang, Yilun Wang, Hang Zhao
                  <br>
                  <em>preprint</em>, 2022
                  <br>
                  <a href="https://tsinghua-mars-lab.github.io/mutr3d/">project page</a>
                  /
                  <a href="https://github.com/a1600012888/MUTR3D">github</a> /
                  <a href="https://arxiv.org/abs/2205.00613">arXiv</a>
                  <p></p>
                  <p>
                    End-to-End 3D tracking with multiview-cameras
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='futr3d_image'>
                      <img src='images/futr3d/figure_futr3d.png' width="180">
                    </div>
                    <img src='images/futr3d/figure_futr3d.png' width="180">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('futr3d_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('futr3d_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2203.10642">
                    <papertitle>FUTR3D: A Unified Sensor Fusion Framework for 3D Detection</papertitle>
                  </a>
                  <br>
                  Xuanyao Chen,
                  <strong>Tianyuan Zhang</strong>,
                  Yue Wang, Yilun Wang, Hang Zhao
                  <br>
                  <em>preprint</em>, 2022
                  <br>
                  <a href="https://tsinghua-mars-lab.github.io/futr3d/">project page</a>
                  /
                  <a href="https://github.com/Tsinghua-MARS-Lab/futr3d">github</a> /
                  <a href="https://arxiv.org/abs/2203.10642">arXiv</a>
                  <p></p>
                  <p>
                    A unified framework for 3D detection from multi-sensor data. We achieved impressive results with
                    multiview-cameras and one-beam LiDAR.
                  </p>
                </td>
              </tr>

              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='obj365_image'>
                      <img src='images/objects365/figure_objects365.png' width="180">
                    </div>
                    <img src='images/objects365/figure_objects365.png' width="180">
                  </div>
                  <script type="text/javascript">
                    function nerfsuper_start() {
                      document.getElementById('obj365_image').style.opacity = "1";
                    }

                    function nerfsuper_stop() {
                      document.getElementById('obj365_image').style.opacity = "0";
                    }
                    nerfsuper_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.objects365.org/overview.html">
                    <papertitle>Objects365: A Large-scale, High-quality Dataset for Object Detection
                    </papertitle>
                  </a>
                  <br>
                  Shuai Shao*, Zeming Li*,
                  <strong>Tianyuan Zhang*</strong>,
                  Chao Peng*, Gang Yu, Xiangyu Zhang, Jing Li, Jian Sun
                  <br>
                  <em>ICCV</em>, 2019
                  <br>
                  <a href="https://www.objects365.org/overview.html">project page</a> /
                  <a
                    href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Shao_Objects365_A_Large-Scale_High-Quality_Dataset_for_Object_Detection_ICCV_2019_paper.pdf">paper</a>
                  <p></p>
                  <p>We provide a <strong>high-quality</strong> large-scale object detection dataset, with 365
                    categories, 638K images,
                    and 10,101K bounding boxes</p>
                </td>
              </tr>

              <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='yopo_image'>
                      <img src='images/yopo/figure_yopo.png' width="180">
                    </div>
                    <img src='images/yopo/figure_yopo.png' width="180">
                  </div>
                  <script type="text/javascript">
                    function refnerf_start() {
                      document.getElementById('yopo_image').style.opacity = "1";
                    }

                    function refnerf_stop() {
                      document.getElementById('yopo_image').style.opacity = "0";
                    }
                    refnerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/1905.00877">
                    <papertitle>You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle
                    </papertitle>
                  </a>
                  <br>
                  Dinghuai Zhang*,
                  <strong>Tianyuan Zhang*</strong>,
                  Yiping Lu*, Zhanxing Zhu, Bin Dong
                  <br>
                  <em>NeurIPS</em>, 2019 &nbsp
                  <br>
                  <a href="https://arxiv.org/abs/1905.00877">arXiv</a>
                  /
                  <a href="https://github.com/a1600012888/YOPO-You-Only-Propagate-Once">code</a>
                  <p></p>
                  <p>Accelerating adversarial training using Pontryagin`s Maximum Principle</p>
                </td>
              </tr>

              <tr onmouseout="atcnn_stop()" onmouseover="atcnn_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='atcnn_image'>
                      <img src='images/atcnn/figure_atcnn.png' width="180">
                    </div>
                    <img src='images/atcnn/figure_atcnn.png' width="180">
                  </div>
                  <script type="text/javascript">
                    function atcnn_start() {
                      document.getElementById('atcnn').style.opacity = "1";
                    }

                    function atcnn_stop() {
                      document.getElementById('atcnn').style.opacity = "0";
                    }
                    atcnn_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/1905.09797">
                    <papertitle>Interpreting Adversarially Trained Convolutional Neural Networks
                    </papertitle>
                  </a>
                  <br>
                  <strong>Tianyuan Zhang</strong>,
                  Zhanxing Zhu
                  <br>
                  <em>ICML</em>, 2019
                  <br>
                  <a href="https://github.com/PKUAI26/AT-CNN">github</a> /
                  <a href="https://arxiv.org/abs/1905.09797">arXiv</a>
                  <p></p>
                  <p>Discussion on the shape-bias and texture-bias of adversarially trainined convolutional neural
                    networks</p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Professional Services</heading>
                  <p>
                    <strong>Reviewer:</strong> CVPR' 2021,23, NeurIPS' 2020, ICLR' 2021,22,23 BlogPosts.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <p font-size:small;>
                    <br>
                    <br>
                  <div style="float:left;">
                    Updated at June. 2023
                  </div>
                  <div style="float:right;">
                    <a href="https://jonbarron.info">Template</a>
                  </div>
                  <br>
                  <div style="float:right;">
                    Template for photography page comes from <a href="https://chenceshi.com/">this amazing guy</a>
                  </div>
                  <br>

                  <br>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
